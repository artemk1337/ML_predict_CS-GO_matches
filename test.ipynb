{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d6d2b32e703f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_parsed_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.hltv.org/results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# list of matches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-d6d2b32e703f>\u001b[0m in \u001b[0;36mget_parsed_page\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;34m\"user-agent\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     }\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\3.6\\lib\\site-packages\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;31m# At this point either we have a TreeBuilder instance in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from re import sub\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle as pk\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "pr = pp.PrettyPrinter()\n",
    "prefix = 'https://www.hltv.org'\n",
    "max_rank = 1000\n",
    "\n",
    "\n",
    "def get_parsed_page(url):\n",
    "    # This fixes a blocked by cloudflare error i've encountered\n",
    "    headers = {\n",
    "        \"referer\": \"https://www.hltv.org/stats\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "    }\n",
    "    return BeautifulSoup(requests.get(url, headers=headers).text, \"lxml\")\n",
    "\n",
    "\n",
    "results = get_parsed_page('https://www.hltv.org/results')\n",
    "\n",
    "# list of matches\n",
    "matches = results.find('div', {\"class\": \"results-all\", 'data-zonedgrouping-group-classes': \"results-sublist\"}).\\\n",
    "    find_all('div', {\"class\": \"result-con\"})\n",
    "\n",
    "\n",
    "def get_teams_url(match_page):\n",
    "    return [prefix + match_page.find_all('div', {\"class\": \"team\"})[0].find('a')['href'],\n",
    "            prefix + match_page.find_all('div', {\"class\": \"team\"})[1].find('a')['href']]\n",
    "\n",
    "\n",
    "# get score\n",
    "def get_score(current_match):\n",
    "    return [int(i.text) for i in current_match.find('td', {'class': 'result-score'}).find_all('span')]\n",
    "\n",
    "\n",
    "# get total_maps\n",
    "def get_total_maps(current_match):\n",
    "    return current_match.find('td', {'class': 'star-cell'}).find('div', {'class': 'map-text'}).text\n",
    "\n",
    "\n",
    "# get star_cell\n",
    "def get_star_cell(current_match):\n",
    "    try:\n",
    "        return len(current_match.find('td', {'class': 'star-cell'}).find_all('i', {'class': 'star'}))\n",
    "    except Exception:\n",
    "        print('None stars')\n",
    "        return 0\n",
    "\n",
    "\n",
    "# get history_h2h\n",
    "def get_history_h2h(match_page):\n",
    "    return [int(i.find('div', {'class': 'bold'}).text) for i in match_page.find_all('div', {'class': 'flexbox-center'})]\n",
    "\n",
    "\n",
    "# get teams_rank\n",
    "def get_team_rank(team):\n",
    "    try:\n",
    "        return max_rank - int(team.find('div', {'class': 'profile-team-stats-container'}).\n",
    "                              find_all('span', {'class': \"right\"})[0].text[1:])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# get teams_top30_for_core\n",
    "def get_top30_for_core(team):\n",
    "    try:\n",
    "        return int(team.find('div', {'class': 'profile-team-stats-container'}).\n",
    "                   find_all('span', {'class': \"right\"})[1].text)\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# get average_ages\n",
    "def get_ave_age(team):\n",
    "    try:\n",
    "        return float(team.find('div', {'class': 'profile-team-stats-container'}).\n",
    "                     find_all('span', {'class': \"right\"})[2].text)\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# get prize_pool\n",
    "def get_prize_pool(event_page):\n",
    "    try:\n",
    "        return int(sub(r'[^\\d.]', '', event_page.find('td', {'class': 'prizepool'}).text))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# get teams_on_tour\n",
    "def get_teams_on_tour(event_page):\n",
    "    return int(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", event_page.find('td', {'class': 'teamsNumber'}).text)[0])\n",
    "\n",
    "\n",
    "# get type_of_tour\n",
    "def get_type_tour(event_page):\n",
    "    tmp = event_page.find('td', {'class': 'location'}).find('span').text\n",
    "    return [i for i in re.split('\\(|\\)| ', tmp) if i is not ''][-1]\n",
    "\n",
    "\n",
    "# get last_5_matches\n",
    "def get_last5_matches(match_page):\n",
    "    def get_url_opponent(url1, i):\n",
    "        return prefix + url1.find_all('tr', {'class': 'table'})[i].find('a', {'class': 'text-ellipsis'})['href']\n",
    "\n",
    "    def get_type_match(url1, i):\n",
    "        return url1.find_all('tr', {'class': 'table'})[i].find('a').text\n",
    "\n",
    "    def get_score_array(url1, i):\n",
    "        return [int(k) for k in\n",
    "                url1.find_all('tr', {'class': 'table'})[i].find('td', {'class': 'spoiler'}).text.split(' - ')]\n",
    "\n",
    "    def get_all(array, table, k):\n",
    "        for i in range(5):\n",
    "            try:\n",
    "                array += [get_type_match(table[k], i),\n",
    "                          get_url_opponent(table[k], i),\n",
    "                          get_team_rank(get_parsed_page(get_url_opponent(table[k], i))),\n",
    "                          *get_score_array(table[k], i)]\n",
    "            except:\n",
    "                array += [None, None, 0, 0, 0]\n",
    "        return array\n",
    "\n",
    "    table_last5_matches = (match_page.find('div', {'class': 'past-matches'}).\n",
    "                           find_all('div', {'class': 'half-width'}))\n",
    "    last5_matches1 = []\n",
    "    last5_matches2 = []\n",
    "    last5_matches1 = get_all(last5_matches1, table_last5_matches, 0)\n",
    "    last5_matches2 = get_all(last5_matches2, table_last5_matches, 1)\n",
    "    return last5_matches1, last5_matches2\n",
    "\n",
    "\n",
    "def get_players(team):\n",
    "    return team.find('div', {'class': 'bodyshot-team'}).find_all('a')\n",
    "\n",
    "\n",
    "def get_players_from_match(match):\n",
    "    return [[i.find('a') for i in k.find_all('td', {'class': 'player'})]\n",
    "            for k in match.find_all('div', {'class': 'lineup standard-box'})]\n",
    "\n",
    "\n",
    "def get_player_stat(player_profile):\n",
    "    stats = []\n",
    "    for i in range(6):\n",
    "        tmp = player_profile.find('div', {'class': 'tab-content'}). \\\n",
    "            find_all('div', {'class': 'cell'})[i]. \\\n",
    "            find('span', {'class': 'statsVal'}).text\n",
    "        if tmp[-1] == '%':\n",
    "            tmp = float(tmp[:-1]) / 100\n",
    "        else:\n",
    "            tmp = float(tmp)\n",
    "        stats += [tmp]\n",
    "    return stats\n",
    "\n",
    "\n",
    "def get_player_age(player_profile):\n",
    "    try:\n",
    "        return int(''.join(\n",
    "            i for i in re.findall('.* years', player_profile.find('div', {'class': 'playerProfile'}).text)[0] if\n",
    "            i.isdigit()))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# get players stats and age\n",
    "def get_players_stat_and_age(team):\n",
    "    players = get_players(team)\n",
    "    ages = []\n",
    "    players_stat = []\n",
    "    for pl in players:\n",
    "        player_profile = get_parsed_page(prefix + pl['href'])\n",
    "        players_stat += [*get_player_stat(player_profile)]\n",
    "        ages += [get_player_age(player_profile)]\n",
    "    return ages, players_stat\n",
    "\n",
    "\n",
    "# get players stats and age from match\n",
    "def get_players_stat_and_age_from_match(match_page):\n",
    "    players_all = get_players_from_match(match_page)\n",
    "    ages = []\n",
    "    players_stat = []\n",
    "    for players in players_all:\n",
    "        for pl in players[:5]:\n",
    "            player_profile = get_parsed_page(prefix + pl['href'])\n",
    "            players_stat += [*get_player_stat(player_profile)]\n",
    "            ages += [get_player_age(player_profile)]\n",
    "    return ages, players_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading https://files.pythonhosted.org/packages/db/64/9426a8636a9551b53e3ba6e9f93a1ca9ba0e56841764d6e0393222ef0bd5/lxml-4.5.1-cp36-cp36m-win_amd64.whl (3.5MB)\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-4.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip3.6 install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <=============== FORMATTING===============> #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_vec_features(current_match):\n",
    "    match_url = prefix + current_match.find('a', {\"class\": \"a-reset\"})['href']  # to DB\n",
    "    match_page = get_parsed_page(match_url)\n",
    "    event_page = get_parsed_page(prefix + match_page.find('div', {'class': 'event'}).find('a')['href'])\n",
    "    teams_pages = [get_parsed_page(i) for i in get_teams_url(match_page)]\n",
    "    team1_url, team2_url = get_teams_url(match_page)  # to DB\n",
    "\n",
    "    last5_matches1, last5_matches2 = get_last5_matches(match_page)  # to DB\n",
    "\n",
    "    history_h2h = get_history_h2h(match_page)  # to DB\n",
    "\n",
    "    rank1, rank2 = get_team_rank(teams_pages[0]), get_team_rank(teams_pages[1])  # to DB\n",
    "\n",
    "    top30_for_core1, top30_for_core2 = get_top30_for_core(teams_pages[0]), get_top30_for_core(teams_pages[1])  # to DB\n",
    "\n",
    "    average_age1, average_age2 = get_ave_age(teams_pages[0]), get_ave_age(teams_pages[1])  # to DB\n",
    "\n",
    "    score1, score2 = get_score(current_match)\n",
    "\n",
    "    total_maps, star_cell = get_total_maps(current_match), get_star_cell(current_match)  # to DB\n",
    "\n",
    "    prize_pool, type_tour, teams_tour = get_prize_pool(event_page),\\\n",
    "                                        get_type_tour(event_page),\\\n",
    "                                        get_teams_on_tour(event_page)\n",
    "\n",
    "    players_age, players_info = get_players_stat_and_age_from_match(match_page)\n",
    "\n",
    "    return [match_url, team1_url, team2_url, *last5_matches1, *last5_matches2, *history_h2h,\n",
    "            rank1, rank2, top30_for_core1, top30_for_core2, average_age1, average_age2,\n",
    "            score1, score2, total_maps, star_cell, prize_pool, type_tour, teams_tour,\n",
    "            *players_age, *players_info]\n",
    "\n",
    "\n",
    "header = ['match_url', 'team1_url', 'team2_url',\n",
    "          *[f'5last_matches1_{k}_{i}' for k in range(10) for i in range(6)],\n",
    "          *[f'5last_matches2_{k}_{i}' for k in range(10) for i in range(6)],\n",
    "          'history_h2h_1win', 'history_h2h', 'history_h2h_2win',\n",
    "          'rank1', 'rank2', 'top30_for_core1', 'top30_for_core2', 'average_age1', 'average_age2',\n",
    "          'score1', 'score2', 'total_maps', 'star_cell', 'prize_pool', 'type_tour', 'teams_tour',\n",
    "          *[f'player{i}_age' for i in range(10)], *[f'player{k}_stat_{i}' for k in range(10) for i in range(6) ]]\n",
    "\n",
    "\n",
    "print(header)\n",
    "data = []\n",
    "data.append(np.asarray(header))\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    if i == 0:\n",
    "        results = get_parsed_page('https://www.hltv.org/results')\n",
    "    else:\n",
    "        results = get_parsed_page(f'https://www.hltv.org/results?offset={i}00')\n",
    "    # list of matches\n",
    "    matches = results.find('div', {\"class\": \"results-all\", 'data-zonedgrouping-group-classes': \"results-sublist\"}). \\\n",
    "        find_all('div', {\"class\": \"result-con\"})\n",
    "    st = 0\n",
    "    for k in range(len(matches)):\n",
    "        st += 1\n",
    "        if st > 5:\n",
    "            break\n",
    "        print(i*100 + k)\n",
    "        try:\n",
    "            data.append(np.asarray(create_vec_features(matches[k])))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "data = np.asarray(data)\n",
    "print(data)\n",
    "df = pd.DataFrame(data=data[1:,:], columns=data[0, :])\n",
    "df.to_csv('df.csv')\n",
    "\n",
    "\n",
    "# https://www.hltv.org/results?offset=100\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/artemkush1/ML_predict_CS-GO_matches/blob/master/data_collect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMGSEIJ3wpF-",
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "import requests\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from re import sub\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "pr = pp.PrettyPrinter()\n",
    "prefix = 'https://www.hltv.org'\n",
    "max_rank = 1000\n",
    "last_months = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmtTE3MDwomc",
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "proxyDict = { \n",
    "              \"http\": 'http://193.169.5.14:39602',\n",
    "            }\n",
    "\n",
    "def get_parsed_page(url):\n",
    "    # This fixes a blocked by cloudflare error i've encountered\n",
    "    headers = {\n",
    "        \"referer\": \"https://www.hltv.org/stats\",\n",
    "        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "    }\n",
    "    got_req = requests.get(url, headers=headers, proxies=None).text\n",
    "    time.sleep(0.15)\n",
    "    return BeautifulSoup(got_req, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for each map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MatchHolder:\n",
    "    def __init__(self, match_url):\n",
    "        self.match_url = match_url\n",
    "        self.match_page = get_parsed_page(match_url)\n",
    "        self.team1_url, self.team2_url = self._get_teams_url()\n",
    "        self.team1_stat_url, self.team2_stat_url = self._get_full_team_stat_page(self.team1_url),\\\n",
    "                                         self._get_full_team_stat_page(self.team2_url)\n",
    "        self.match_date = datetime.datetime.utcfromtimestamp(int(self._get_unixtime_match()))\n",
    "        self.maps_played_with_score = self.get_score_on_each_map()\n",
    "        self.history_h2h = self.get_history_h2h()\n",
    "        self.team1_page, self.team2_page = get_parsed_page(self.team1_url), get_parsed_page(self.team2_url)\n",
    "        self.team1_rank, self.team2_rank = self.get_team_rank(self.team1_page), self.get_team_rank(self.team2_page)\n",
    "        self.event_page = self._get_event_page()\n",
    "        self.prize_pool = self.get_prize_pool()\n",
    "        self.count_teams_on_tour = self.get_teams_on_tour()\n",
    "        self.players_url = self.get_players_from_match_url()\n",
    "        (self.players_stats_last3m, self.players_stats_last6m) = self.get_stats_each_player()\n",
    "         #self.players_stats_last1m,\n",
    "         #self.players_stats_last9m,\n",
    "         #self.players_stats_last12m...\n",
    "        self.maps_team1, self.maps_team2 = self.get_maps_url(self.team1_stat_url), self.get_maps_url(self.team2_stat_url)\n",
    "        self.stat_maps_team1, self.stat_maps_team2 = self.get_maps_stat_dict(self.maps_team1, 'team1',\n",
    "                                                            skip_params=['Wins / draws / losses'],\n",
    "                                                            maps_need=[i for i in self.maps_played_with_score][0]), \\\n",
    "                                                     self.get_maps_stat_dict(self.maps_team2, 'team2',\n",
    "                                                            skip_params=['Wins / draws / losses'],\n",
    "                                                            maps_need=[i for i in self.maps_played_with_score[0]])\n",
    "        self.last5matches = self.get_last5_matches_v1_2teams()\n",
    "        self.pistol_rounds = self.get_pistols_rounds()\n",
    "        \n",
    "    def _get_teams_url(self):\n",
    "        return [prefix + self.match_page.find_all('div', {\"class\": \"team\"})[0].find('a')['href'],\n",
    "                prefix + self.match_page.find_all('div', {\"class\": \"team\"})[1].find('a')['href']]\n",
    "    \n",
    "    def _get_full_team_stat_page(self, team_url):\n",
    "        return f'https://www.hltv.org/stats/teams/maps{team_url.split(\"https://www.hltv.org/team\")[-1]}'\n",
    "    \n",
    "    def _get_unixtime_match(self):\n",
    "        return self.match_page.find('div', {\"class\": \"timeAndEvent\"}).find('div', {\"class\": \"time\"})['data-unix'][:-3]\n",
    "    \n",
    "    def _get_event_page(self):\n",
    "        return get_parsed_page(prefix + self.match_page.find('div', {'class': 'event'}).find('a')['href'])\n",
    "    \n",
    "    # return {maps: score on map}, total-maps-counter\n",
    "    def get_score_on_each_map(self):\n",
    "        def _get_maps_():\n",
    "            maps_score = []\n",
    "            maps_obj = self.match_page.find('div', {\"class\": \"flexbox-column\"}).find_all('div', {\"class\": \"mapholder\"})\n",
    "            for i in maps_obj:\n",
    "                tmp = i.find('div', {\"class\": \"played\"})\n",
    "                if tmp:\n",
    "                    maps_score += [i]\n",
    "            return maps_score\n",
    "\n",
    "        maps_obj = _get_maps_()\n",
    "        # print(len(maps_obj))\n",
    "        maps = {}\n",
    "        i = 0\n",
    "        for map_ in maps_obj:\n",
    "            tmp1 = int(map_.find('div', {\"class\": \"results-left\"}).find('div', {\"class\": \"results-team-score\"}).text)\n",
    "            tmp2 = int(map_.find('span', {\"class\": \"results-right\"}).find('div', {\"class\": \"results-team-score\"}).text)\n",
    "            if len([tmp1, tmp2]) != 2:\n",
    "                print(\"Problems in get_score()\")\n",
    "            maps[map_.find('div', {\"class\": \"mapname\"}).text] = [tmp1, tmp2]\n",
    "            i += 1\n",
    "        return maps, i\n",
    "    \n",
    "    # get history_h2h: expect 3 params\n",
    "    def get_history_h2h(self):\n",
    "        tmp = [int(i.find('div', {'class': 'bold'}).text) for i in\n",
    "               self.match_page.find_all('div', {'class': 'flexbox-center'})]\n",
    "        if len(tmp) != 3:\n",
    "            print(\"Problems in get_history_h2h()\")\n",
    "        return tmp\n",
    "    \n",
    "    # get teams_rank: expect 1 param\n",
    "    def get_team_rank(self, team):\n",
    "        try:\n",
    "            tmp = max_rank - int(team.find('div', {'class': 'profile-team-stats-container'}).\n",
    "                                 find_all('span', {'class': \"right\"})[0].text[1:])\n",
    "            if not tmp:\n",
    "                return 0\n",
    "            return tmp\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    # get prize_pool: expect 1 param\n",
    "    def get_prize_pool(self):\n",
    "        try:\n",
    "            tmp = int(sub(r'[^\\d.]', '', self.event_page.find('td', {'class': 'prizepool'}).text))\n",
    "            if not tmp:\n",
    "                return 0\n",
    "            return tmp\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    # get teams_on_tour: expect 1 param\n",
    "    def get_teams_on_tour(self):\n",
    "        tmp = int(re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", self.event_page.find('td', {'class': 'teamsNumber'}).text)[0])\n",
    "        if tmp:\n",
    "            return tmp\n",
    "        return 0\n",
    "    \n",
    "    # expect 2 * 5 params\n",
    "    def get_players_from_match_url(self):\n",
    "        \"\"\"tmp = [[prefix + '/stats/players' + (i.find('a')['href'].split('/player')[-1])\n",
    "                 for i in k.find_all('td', {'class': 'player'})][:5]\n",
    "                for k in self.match_page.find_all('div', {'class': 'lineup standard-box'})]\"\"\"\n",
    "        tmp = {}\n",
    "        all_pl = self.match_page.find_all('div', {'class': 'lineup standard-box'})\n",
    "        for k in range(2):\n",
    "            for i in range(5):\n",
    "                try:\n",
    "                    tmp[f'team{k}_pl{i}'] = prefix + '/stats/players' + \\\n",
    "                            (all_pl[k].find_all('td', {'class': 'player'})[i].find('a')['href'].split('/player')[-1])\n",
    "                except:\n",
    "                    tmp[f'team{k}_pl{i}'] = \"\"\n",
    "        return tmp\n",
    "\n",
    "    # expect 19 params in dict\n",
    "    def _get_player_many_stats(self, player, index):\n",
    "        table_up = player.find('div', {'class': 'statistics'}).find_all('div', {'class': 'stats-row'})\n",
    "        res = {}\n",
    "        for i in table_up:\n",
    "            tmp1 = i.find_all('span')[-1].text\n",
    "            if tmp1[-1] == '%':\n",
    "                tmp1 = float(tmp1[:-1]) / 100\n",
    "            elif tmp1[-1] == '-':\n",
    "                tmp1 = '0'\n",
    "            res[i.find_all('span')[0].text + index] = tmp1\n",
    "        table_down = player.find('div', {'class': 'featured-ratings-container'}).find_all('div', {'class': 'col-custom'})\n",
    "        for i in table_down:\n",
    "            tmp1 = i.find('div', {'class': 'rating-value'}).text\n",
    "            if tmp1[-1] == '%':\n",
    "                tmp1 = float(tmp1[:-1]) / 100\n",
    "            elif tmp1[-1] == '-':\n",
    "                tmp1 = '0'\n",
    "            res[i.find('div', {'class': 'rating-description'}).text + index] = tmp1\n",
    "        if len(res) != 19:\n",
    "            print(\"Problems in get_player_many_stats()\")\n",
    "        return res\n",
    "\n",
    "    # return dict with 19 params\n",
    "    def _get_player_stat_in_period(self, player_url, date_start, date_end, index):\n",
    "        player_page = get_parsed_page(player_url + \\\n",
    "                      f'?startDate={date_start.strftime(\"%Y-%m-%d\")}&endDate={date_end.strftime(\"%Y-%m-%d\")}')\n",
    "        return self._get_player_many_stats(player_page, index)\n",
    "    \n",
    "    # return 5 big dict: in each 5 players with 19 params\n",
    "    def get_stats_each_player(self):\n",
    "        _1m = {}\n",
    "        _3m = {}\n",
    "        _6m = {}\n",
    "        #_9m = {}\n",
    "        #_12m = {}\n",
    "        for dict_, months in zip([_1m, _3m, _6m],\n",
    "                     [1, 3, 6]):\n",
    "            for i in self.players_url:\n",
    "                # print(i)\n",
    "                try:\n",
    "                    dict_[i] = [self._get_player_stat_in_period(self.players_url[i],\n",
    "                                                                self.match_date - relativedelta(months=months),\n",
    "                                                                self.match_date - relativedelta(days=1),\n",
    "                                                                '_'+i)]\n",
    "                except Ex:\n",
    "                    dict_[i] = [0 for t in range(19)]\n",
    "        return _1m, _3m  # , _6m, _9m, _12m\n",
    "\n",
    "    # get url on maps\n",
    "    def get_maps_url(self, team_url_maps):\n",
    "        dict_ = {}\n",
    "        # print(team_url_maps)\n",
    "        maps = get_parsed_page(team_url_maps).find('div', {'class': 'two-grid'}).find_all('div', {'class': 'map-pool'})\n",
    "        for i in maps:\n",
    "            dict_[i.find('img', {'class': 'map-pool-map'})['title']] = prefix + i.find('a')['href']\n",
    "        return dict_\n",
    "    \n",
    "    # expect (10 - skip_params) parameters in dict\n",
    "    def _get_map_many_stats(self, map_page, index, skip_params):\n",
    "        table = map_page.find('div', {'class': 'stats-rows'}).find_all('div', {'class': 'stats-row'})\n",
    "        stats = {}\n",
    "        for k in table:\n",
    "            if k.find_all('span')[0].text not in skip_params:\n",
    "                tmp = k.find_all('span')[-1].text\n",
    "                if tmp[-1] == '%':\n",
    "                    tmp = float(tmp[:-1]) / 100\n",
    "                elif tmp[-1] == '-':\n",
    "                    tmp = 0\n",
    "                stats[k.find_all('span')[0].text + index] = float(tmp)\n",
    "        if len(stats) != (10 - len(skip_params)):\n",
    "            print(\"Problems in get_stats_on_each_map() (10 params)\")\n",
    "        return stats\n",
    "    \n",
    "    # expect dict\n",
    "    def _get_maps_stat_in_period(self, match_url, date_start, date_end, index, skip_params):\n",
    "        map_page = get_parsed_page(match_url + \\\n",
    "                      f'?startDate={date_start.strftime(\"%Y-%m-%d\")}&endDate={date_end.strftime(\"%Y-%m-%d\")}')\n",
    "        return self._get_map_many_stats(map_page, index, skip_params)\n",
    "\n",
    "    # expect 5 big DICTS with (10 - skip_params) parameters in each map\n",
    "    def get_maps_stat_dict(self, maps, index, skip_params=[], maps_need=None):\n",
    "        # self.maps_team1, self.maps_team2\n",
    "        _1m = {}\n",
    "        _3m = {}\n",
    "        _6m = {}\n",
    "        #_9m = {}\n",
    "        #_12m = {}\n",
    "        for dict_, months in zip([_1m, _3m, _6m],\n",
    "                     [1, 3, 6, 9, 12]):\n",
    "            for i in maps:\n",
    "                # print(i)\n",
    "                if i in maps_need:\n",
    "                    dict_[i] = [self._get_maps_stat_in_period(maps[i],\n",
    "                               self.match_date - relativedelta(months=months),\n",
    "                               self.match_date - relativedelta(days=1),\n",
    "                               '_'+index, skip_params)]\n",
    "                elif maps_need is None:\n",
    "                    dict_[i] = [self._get_maps_stat_in_period(maps[i],\n",
    "                               self.match_date - relativedelta(months=months),\n",
    "                               self.match_date - relativedelta(days=1),\n",
    "                               '_'+index, skip_params)]\n",
    "        return [_1m, _3m]  # , _6m, _9m, _12m\n",
    "\n",
    "\n",
    "    # get lats 5 matches for both teams: expect 5 params in 2 dicts in 2 other dicts\n",
    "    def get_last5_matches_v1_2teams(self):\n",
    "        def get_url_opponent(url1, i):\n",
    "            return prefix + url1.find_all('tr', {'class': 'table'})[i].find('a', {'class': 'text-ellipsis'})['href']\n",
    "\n",
    "        def get_type_match(url1, i):\n",
    "            return url1.find_all('tr', {'class': 'table'})[i].find('a', {'data-link-tracking-page': 'Matchpage'}).text\n",
    "\n",
    "        def get_score_array(url1, i):\n",
    "            return [int(k) for k in\n",
    "                    url1.find_all('tr', {'class': 'table'})[i].find('td', {'class': 'spoiler'}).text.split(' - ')]\n",
    "\n",
    "        def get_all(table):\n",
    "            team_ranks = {}\n",
    "            team_scores = {}\n",
    "            for i in range(5):\n",
    "                try:\n",
    "                    rank_ = self.get_team_rank(get_parsed_page(get_url_opponent(table, i)))\n",
    "                    score1_, score2_ = get_score_array(table, i)\n",
    "                    team_ranks[f'opponent_rank_from_5_last_matches_{i}'] = rank_\n",
    "                    # print('scores last 5 matches:', score1_, score2_)\n",
    "                    if score1_ > score2_:\n",
    "                        team_scores[f'win/loss_from_5_last_matches_{i}'] = 1\n",
    "                    else:\n",
    "                        team_scores[f'win/loss_from_5_last_matches_{i}'] = -1\n",
    "                except Exception as e:\n",
    "                    print('Problems in get_last5_matches_v1_2teams()', e)\n",
    "                    team_ranks[f'opponent_rank_from_5_last_matches_{i}'] = '0'\n",
    "                    team_scores[f'win/loss_from_5_last_matches_{i}'] = 0\n",
    "            return team_ranks, team_scores\n",
    "        last5m = {}\n",
    "        tables = (self.match_page.find('div', {'class': 'past-matches'}).\n",
    "                 find_all('div', {'class': 'half-width'}))\n",
    "        last5m['team1'] = [get_all(tables[0])]\n",
    "        last5m['team2'] = [get_all(tables[1])]\n",
    "        # last5_matches_2teams = [*types, *teams_rank, *scores]\n",
    "        if len(last5m) != 2:\n",
    "            print('Problems in get_last5_matches_v1_2teams()')\n",
    "        return last5m\n",
    "\n",
    "    def get_pistols_rounds(self):\n",
    "        def _get_maps_():\n",
    "            maps_score = []\n",
    "            maps_obj = self.match_page.find('div', {\"class\": \"flexbox-column\"}).find_all('div', {\"class\": \"mapholder\"})\n",
    "            for i in maps_obj:\n",
    "                tmp = i.find('div', {\"class\": \"played\"})\n",
    "                if tmp:\n",
    "                    maps_score += [i]\n",
    "            return maps_score\n",
    "\n",
    "        maps_obj = _get_maps_()\n",
    "        # print(len(maps_obj))\n",
    "        maps = {}\n",
    "        i = 0\n",
    "        for map_ in maps_obj:\n",
    "            tmp = prefix + map_.find('div', {\"class\": \"results-center\"}).\\\n",
    "                                find('a', {\"class\": \"results-stats\"})['href']\n",
    "            page_stat = get_parsed_page(tmp)\n",
    "            tables = page_stat.find_all('div', {\"class\": \"round-history-half\"})[:2]\n",
    "            pistols = {}\n",
    "            n = 1\n",
    "            for k in tables:\n",
    "                if k.find('img', {\"class\": \"round-history-outcome\"})['src'] !=\\\n",
    "                            '//static.hltv.org/images/scoreboard/emptyHistory.svg':\n",
    "                    pistols[f'pistol_round_{n}'] = 1\n",
    "                else:\n",
    "                    pistols[f'pistol_round_{n}'] = -1\n",
    "                n += 14\n",
    "            maps[map_.find('div', {\"class\": \"mapname\"}).text] = [pistols]\n",
    "        return maps\n",
    "\n",
    "\n",
    "\n",
    "# get_metches_url(filename='matches.txt', pages_with_results=[0, 1])\n",
    "# cl = MatchHolder('https://www.hltv.org/matches/2341715/vitality-vs-dignitas-blast-premier-spring-2020-europe-showdown')\n",
    "# print(cl.stat_maps_team1)\n",
    "# cl.pistol_rounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSK4Tzz_92oT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download all urls matches\n",
    "def get_matches_url(filename=None, pages_with_results=[0]):\n",
    "    all_matches = []\n",
    "    for i in pages_with_results:\n",
    "        if i == 0:\n",
    "            results = get_parsed_page('https://www.hltv.org/results')\n",
    "        else:\n",
    "            results = get_parsed_page(f'https://www.hltv.org/results?offset={i}00')\n",
    "        # list of matches\n",
    "        all_matches += [prefix + url_.find('a', {\"class\": \"a-reset\"})['href'] for url_ in\n",
    "                        results.find('div',\n",
    "                                     {\"class\": \"results-all\", 'data-zonedgrouping-group-classes': \"results-sublist\"}).\n",
    "                        find_all('div', {\"class\": \"result-con\"})]\n",
    "    all_matches = np.array(all_matches)\n",
    "    # print(all_matches)\n",
    "    if filename is None:\n",
    "        return all_matches\n",
    "    else:\n",
    "        np.save(filename, np.array(all_matches))\n",
    "\n",
    "\n",
    "get_matches_url(filename='all_matches', pages_with_results=[i for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJle_jKW1XC4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cl = MatchHolder('https://www.hltv.org/matches/2341715/vitality-vs-dignitas-blast-premier-spring-2020-europe-showdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pist_r(stat, name):\n",
    "    res = []\n",
    "    lb = []\n",
    "    for i in stat[name][0]:\n",
    "        res += [stat[name][0][i]]\n",
    "        lb += [i]\n",
    "    return res, lb\n",
    "    \n",
    "\n",
    "\n",
    "def get_big_stat_map(stat, index, name):\n",
    "    res = []\n",
    "    lb = []\n",
    "    for i in stat[index][name][0]:\n",
    "        res += [stat[index][name][0][i]]\n",
    "        lb += [i]\n",
    "    return res, lb\n",
    "\n",
    "def get_big_player_stat(stat):\n",
    "    labels = []\n",
    "    res = []\n",
    "    for player in stat:\n",
    "        for k in stat[player][0]:\n",
    "            labels += [k]\n",
    "            res += [stat[player][0][k]]\n",
    "    return res, labels\n",
    "\n",
    "def get_last_5m(stat):\n",
    "    labels = []\n",
    "    res = []\n",
    "    for i in stat:\n",
    "        for k in stat[i][0]:\n",
    "            for j in k:\n",
    "                labels += [j]\n",
    "                res += [k[j]]\n",
    "    return res, labels\n",
    "\n",
    "def prepare_maps_played(stat):\n",
    "    dict_ = {}\n",
    "    for i in stat:\n",
    "        dict_[i] = ['score1', 'score2']\n",
    "    return stat, dict_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FINAL_DICT = {0: None,\n",
    "              1: None}\n",
    "\n",
    "\n",
    "def final_def(cl):\n",
    "    # Взял статистику по всем картам и количество сыгранных карт\n",
    "    maps_played, maps_total = cl.maps_played_with_score  # added\n",
    "    maps_played_score, lab_maps_played = prepare_maps_played(maps_played)  # added\n",
    "\n",
    "\n",
    "    ranks_score_last5, labels_last5 = get_last_5m(cl.last5matches)  # added\n",
    "\n",
    "\n",
    "    data_1m = []\n",
    "    data_2m = []\n",
    "    data_3m = []\n",
    "\n",
    "\n",
    "    # Рассматриваем одну из карт\n",
    "    for name in maps_played_score:\n",
    "        score = maps_played_score[name]  # added\n",
    "        lbscore = lab_maps_played[name]  # added\n",
    "        # Сохраняем данные за разный период\n",
    "        for i, big_data_map in zip([0, 1], [cl.players_stats_last3m,\n",
    "                                            cl.players_stats_last6m]):\n",
    "            player_stat, lab_pl_stat = get_big_player_stat(big_data_map)  # OK  # added\n",
    "            maps_stat1, lab_map_stat1 = get_big_stat_map(cl.stat_maps_team1, i, name)  # OK  # added\n",
    "            maps_stat2, lab_map_stat2 = get_big_stat_map(cl.stat_maps_team2, i, name)  # OK  # added\n",
    "            pist, lbpist = get_pist_r(cl.pistol_rounds, name)\n",
    "\n",
    "            final_data = np.array\\\n",
    "            ([cl.match_url, *score, maps_total, cl.maps_played_with_score[1], *pist,\n",
    "              *cl.history_h2h,\n",
    "             cl.team1_rank, cl.team2_rank,\n",
    "             cl.prize_pool, cl.count_teams_on_tour, \n",
    "             *ranks_score_last5, *player_stat, *maps_stat1, *maps_stat2\n",
    "            ])\n",
    "\n",
    "            labels = np.array\\\n",
    "            (['url', *lbscore, 'maps_total', 'maps_total', *lbpist,\n",
    "              'history_t1', 'history_draw', 'history_t2',\n",
    "             'team1_rank', 'team2_rank',\n",
    "             'prize_pool', 'teams_on_tour',\n",
    "             *labels_last5, *lab_pl_stat, *lab_map_stat1, *lab_map_stat2\n",
    "            ])\n",
    "\n",
    "            if FINAL_DICT[i] is None:\n",
    "                FINAL_DICT[i] = pd.DataFrame([final_data],\n",
    "                                             columns=labels)\n",
    "            else:\n",
    "                FINAL_DICT[i] = pd.concat([FINAL_DICT[i],\n",
    "                                           pd.DataFrame([final_data],\n",
    "                                                        columns=labels)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.hltv.org/matches/2341894/havu-vs-endpoint-home-sweet-home-cup-7\n",
      "https://www.hltv.org/matches/2341832/fate-vs-espada-winners-league-season-4-europe\n"
     ]
    }
   ],
   "source": [
    "matches = np.load('all_matches.npy', allow_pickle=True)\n",
    "\n",
    "for match in matches:\n",
    "    print(match)\n",
    "    cl = MatchHolder(match)\n",
    "    try:\n",
    "        final_def(cl)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    for i in FINAL_DICT:\n",
    "        FINAL_DICT[i].to_csv(f'df_{i}.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "colab_type": "code",
    "id": "TvdpL3ZHYAET",
    "outputId": "8706c494-bc8c-41b4-9e06-136124651780",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "data_save = np.array(data)\n",
    "df = pd.DataFrame(data=data_save[1:,:], columns=data_save[0, :])\n",
    "df.to_csv('/content/drive/My Drive/Colab Notebooks/cs-go_matches/df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y99PnsvDwit0",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO92asABd2uZ8SCAY3Y1m3s",
   "include_colab_link": true,
   "name": "data_collect.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
